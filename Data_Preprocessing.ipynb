{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T09:00:59.801317Z",
     "start_time": "2021-05-22T09:00:59.782384Z"
    }
   },
   "source": [
    "# DATA PREPROCESSING STEPS\n",
    "\n",
    "To do the preprocessing, we create a class of object called **YearlyFiling13F** that store all the information of top invest managers in a particular year. \n",
    "\n",
    "To create the object, follow 3 steps:\n",
    "- Base on 'https://www.advratings.com/top-asset-management-firms' to filter the top investors in market stored in *funds_list*\n",
    "- Find all urls related to those investors to 13F-HR filing data from SEC Edgar database in a particular year stored in *urls*\n",
    "- Fetch all the neccessary information stored in *data_dict* & *names_dict*\n",
    "\n",
    "This object has below important attributes:\n",
    "- funds_list: the list of top investor's names\n",
    "- urls: store all urls to get 13F-HR filing data from SEC Edgar database of top investmanager\n",
    "- data_dict: a nested dictionary for each CIK contains a dictionary of {issuer : total_amount}\n",
    "- names_dict: a dictionary linking cik to the name\n",
    "\n",
    "This object has below important function: \n",
    "- create_JSON_files() : Create a JSON file to store and retrieve a dict of data for desired year, facilitate simpler analysis steps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T06:29:54.994796Z",
     "start_time": "2021-05-31T06:29:52.207999Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T06:29:55.030858Z",
     "start_time": "2021-05-31T06:29:54.996705Z"
    }
   },
   "outputs": [],
   "source": [
    "class YearlyFiling13F:\n",
    "    \"\"\" \n",
    "        Class represent an object containing stock portfolio information from top investor in a particular year.\n",
    "        To obtain the neccessary information, perform 3 steps:\n",
    "        1. Base on 'https://www.advratings.com/top-asset-management-firms' to filter the top investors in market\n",
    "        2. Find 13F-HR filing data from SEC Edgar database for those investors in a particular year\n",
    "        3. Create a JSON file to store and retrieve a dict of data for desired year, facilitate simpler analysis steps.\n",
    "    \"\"\"\n",
    "    \n",
    "    # If True prints out results in console\n",
    "    debug = False\n",
    "    \n",
    "    \"\"\" \n",
    "        Get the biggest investment managers \n",
    "        - Scraping the website: 'https://www.advratings.com/top-asset-management-firms' to get name of top investors\n",
    "        - Storing the list of top investor's names in funds_list\n",
    "    \"\"\"\n",
    "    def __init__(self,year=''):\n",
    "        funds_list = []\n",
    "        url = 'https://www.advratings.com/top-asset-management-firms'\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        for row in soup.findAll('table')[0].tbody.findAll('tr'):\n",
    "            company = str(row.findAll('td')[1].contents)\n",
    "            company = re.split(r'<|>', company)\n",
    "            if(len(company) > 2):\n",
    "                #exluding any special chars and wite spaces from company names\n",
    "                company = ''.join(e for e in company[2] if e.isalnum())\n",
    "                funds_list.append(company.upper())\n",
    "            else:\n",
    "                company = re.split(r'([\\'|\\'])', company[0])\n",
    "                #exluding any special chars and wite spaces from company names\n",
    "                company = ''.join(e for e in company[2] if e.isalnum())\n",
    "                funds_list.append(company.upper())\n",
    "        \"\"\" Initialize object \"\"\"\n",
    "        self.funds_list = funds_list[1:]\n",
    "        self.filepath = (glob.glob(\"13F/*\" + year + \".txt\"))[0] # Path of file\n",
    "        self.year = year\n",
    "        self.get_URLs(self.filepath)\n",
    "        # Directly call parse_file() when year is provided\n",
    "            \n",
    "    def get_URLs(self, filepath=''):\n",
    "        \"\"\" Parses relevant information from 13F-HR text file \n",
    "            Getting paths to all 13F-HR filing per quarter\n",
    "            Choosing only files from funds_list - list of the top asset investment managers\n",
    "        \"\"\"\n",
    "        self.filepath = filepath # Path of file\n",
    "        \n",
    "        all_urls = {}\n",
    "        path = 'https://www.sec.gov/Archives/'\n",
    "        file = open(filepath, 'r')\n",
    "        forms_url = []\n",
    "        for line in file:\n",
    "            #parsing out the company name from the list\n",
    "            company = re.findall(r'13F-HR\\s*\\d*([\\D+\\s\\D+]*)\\s*\\d*', line)\n",
    "            #string processing to get uniform formatting\n",
    "            company = ''.join(e for e in company)\n",
    "            company = company.replace(' ', '')\n",
    "            company = re.sub('\\d', '', company)\n",
    "            company = company.upper()\n",
    "            #finding the investment managers that match the list of the top investment mangers *fund_list*\n",
    "            for name in self.funds_list:\n",
    "                if (company in name or name in company) and len(company) > 3:\n",
    "                    splitted = line.split()\n",
    "                    forms_url.append(path + splitted[-1])\n",
    "\n",
    "        #adding a key:value pair to a dict. - contains \n",
    "        all_urls[file.name.split('/')[-1]] = forms_url\n",
    "        self.urls = forms_url\n",
    "        # parsing data from urls\n",
    "        data_dict = {} #nested dictionary for each CIK contains a dictionary of {issuer : total_amount}\n",
    "        names_dict = {} #a dictionary linking cik to the name\n",
    "        \n",
    "        for url in forms_url: \n",
    "            page = requests.get(url)\n",
    "            data = page.text\n",
    "            soup = BeautifulSoup(data, \"lxml\")\n",
    "\n",
    "            cik_pattern = r'\\s*CENTRAL INDEX KEY:\\s*(\\w[\\w*|\\s*]*)\\n'\n",
    "            cik_key = re.findall(cik_pattern, data)\n",
    "            cik_key = str(cik_key[0]) if cik_key != [] else None\n",
    "            data_dict[cik_key] = {}\n",
    "\n",
    "            name_pattern = r'\\s*COMPANY CONFORMED NAME:\\s*(\\w[\\w*|\\s*]*)\\n*'\n",
    "            name = re.findall(name_pattern, data)\n",
    "            name = name[0].split('\\n') if name != [] else None \n",
    "            names_dict[cik_key] = name[0] if name != None else None\n",
    "\n",
    "            stocklist = soup.find_all('infotable')\n",
    "            for s in stocklist:\n",
    "\n",
    "                if s.find(\"ns1:nameofissuer\") != None:\n",
    "                    # Company name\n",
    "                    n = s.find(\"ns1:nameofissuer\").string\n",
    "                    if n in data_dict[cik_key].keys():\n",
    "                        #Create only a record if the issuer is unique, oterwise sum the amount of stocks\n",
    "                        data_dict[cik_key][n] = data_dict[cik_key].get(n) + int(s.find(\"ns1:shrsorprnamt\").find(\"ns1:sshprnamt\").string)# Company name\n",
    "                    else:\n",
    "                        data_dict[cik_key][n] = int(s.find(\"ns1:shrsorprnamt\").find(\"ns1:sshprnamt\").string)\n",
    "\n",
    "                else:\n",
    "                    n = s.find(\"nameofissuer\").string\n",
    "                    if n in data_dict[cik_key].keys():\n",
    "                        #Create only a record if the issuer is unique, oterwise sum the amount of stocks\n",
    "                        data_dict[cik_key][n] = data_dict[cik_key].get(n) + int(s.find(\"shrsorprnamt\").find(\"sshprnamt\").string)\n",
    "                    else:\n",
    "                        data_dict[cik_key][n] = int(s.find(\"shrsorprnamt\").find(\"sshprnamt\").string)\n",
    "        \n",
    "        #Removing ciks/issuers with empty dictionary\n",
    "        self.data_dict = dict(filter(lambda sub: sub[1], data_dict.items()))\n",
    "        self.names_dict = dict(filter(lambda sub: sub[1], names_dict.items()))\n",
    "        return\n",
    "    \n",
    "    def create_JSON_files(self):\n",
    "        \"\"\" Create JSON file \"\"\"\n",
    "        with open('json_pipeline/data'+ self.year +'.json', 'w') as json_file:\n",
    "            json.dump(self.data_dict, json_file)\n",
    "\n",
    "        with open('json_pipeline/names'+ self.year +'.json', 'w') as json_file:\n",
    "            json.dump(self.names_dict, json_file)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACT DATA AND CREATE JSON_FILES\n",
    "\n",
    "In this step, we will initiate all the data that neccessary for analysis, we can choose the numbers of year freely, depend on the purpose of analysis.\n",
    "\n",
    "Steps:\n",
    "- select 1 year and fill this in in YearlyFilin13F\n",
    "- create the JSON_files\n",
    "\n",
    "In particular report, we do the analysis from 2018 to 2021, create 4 objects and related JSON files: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T06:36:22.581663Z",
     "start_time": "2021-05-31T06:29:55.554755Z"
    }
   },
   "outputs": [],
   "source": [
    "#step1\n",
    "Filing2018 = YearlyFiling13F('2018')\n",
    "\n",
    "Filing2019 = YearlyFiling13F('2019')\n",
    "\n",
    "Filing2020 = YearlyFiling13F('2020')\n",
    "\n",
    "Filing2021 = YearlyFiling13F('2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T06:40:50.485845Z",
     "start_time": "2021-05-31T06:40:45.222413Z"
    }
   },
   "outputs": [],
   "source": [
    "#step2\n",
    "Filing2018.create_JSON_files()\n",
    "\n",
    "Filing2019.create_JSON_files()\n",
    "\n",
    "Filing2020.create_JSON_files()\n",
    "\n",
    "Filing2021.create_JSON_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
