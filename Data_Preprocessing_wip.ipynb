{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the biggest investment managers\n",
    "* scraping the website: https://www.advratings.com/top-asset-management-firms containing the list of the top asset mangement firms\n",
    "* processing the name of the of the company\n",
    "* storing the list of all the companies in funds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funds_list = []\n",
    "\n",
    "url = 'https://www.advratings.com/top-asset-management-firms'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "for row in soup.findAll('table')[0].tbody.findAll('tr'):\n",
    "    company = str(row.findAll('td')[1].contents)\n",
    "    company = re.split(r'<|>', company)\n",
    "    if(len(company) > 2):\n",
    "        #exluding any special chars and wite spaces from company names\n",
    "        company = ''.join(e for e in company[2] if e.isalnum())\n",
    "        funds_list.append(company.upper())\n",
    "    else:\n",
    "        company = re.split(r'([\\'|\\'])', company[0])\n",
    "        #exluding any special chars and wite spaces from company names\n",
    "        company = ''.join(e for e in company[2] if e.isalnum())\n",
    "        funds_list.append(company.upper())\n",
    "\n",
    "#deleting the first record (remainder of the header)\n",
    "funds_list = funds_list[1:]\n",
    "len(funds_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dictionary of {Year : URL list} \n",
    "* Getting path to all 13F-HR filing per quarter \n",
    "* Each file corresponds to quater 1, the files are for years 2021 - 2018 \n",
    "* Choosing only files from **funds_list** - list of the top asset investment managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_years_urls = {}\n",
    "path = 'https://www.sec.gov/Archives/'\n",
    "companies = []\n",
    "\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "\n",
    "file_2021 = open('/home/ivana/Environments/env/Data_Preprocessing/13F_2021.txt', 'r')\n",
    "file_2020 = open('/home/ivana/Environments/env//Data_Preprocessing/13F_2020.txt', 'r')\n",
    "file_2019 = open('/home/ivana/Environments/env//Data_Preprocessing/13F_2019.txt', 'r')\n",
    "file_2018 = open('/home/ivana/Environments/env//Data_Preprocessing/13F_2018.txt', 'r')\n",
    "\n",
    "files = [file_2021, file_2020, file_2019, file_2018]\n",
    "\n",
    "for file in files:\n",
    "    forms_url = []\n",
    "    for line in file:\n",
    "        \n",
    "        #parsing out the company name from the list\n",
    "        company = re.findall(r'13F-HR\\s*\\d*([\\D+\\s\\D+]*)\\s*\\d*', line)\n",
    "        \n",
    "        #string processing to get uniform formatting\n",
    "        company = ''.join(e for e in company)\n",
    "        company = company.replace(' ', '')\n",
    "        company = re.sub('\\d', '', company)\n",
    "        company = company.upper()\n",
    "\n",
    "        \n",
    "        #finding the investment managers that match the list of the top investment mangers *fund_list*\n",
    "        for name in funds_list:\n",
    "            if (company in name or name in company) and len(company) > 3:\n",
    "                splitted = line.split()\n",
    "                forms_url.append(path + splitted[-1])\n",
    "                \n",
    "    #adding a key:value pair to a dict. - contains \n",
    "    all_years_urls[file.name.split('/')[-1]] = forms_url\n",
    "\n",
    "#finding out how many \n",
    "len(all_years_urls.get('13F_2021.txt'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the connection to the ArangoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database is already created\n"
     ]
    }
   ],
   "source": [
    "from pyArango.connection import *\n",
    "from arango import ArangoClient\n",
    "client = ArangoClient(hosts=\"http://localhost:8529\")\n",
    "db = client.db('_system', username=\"root\", password=\"networks\")\n",
    "\n",
    "\n",
    "try:\n",
    "    db.create_database('networks')\n",
    "    graph = db.create_graph('networks')\n",
    "\n",
    "    students = graph.create_vertex_collection(\"investors\")\n",
    "    lectures = graph.create_vertex_collection(\"issuers\")\n",
    "\n",
    "    edges = graph.create_edge_definition(\n",
    "        edge_collection=\"investments\",\n",
    "        from_vertex_collections=[\"investors\"],\n",
    "        to_vertex_collections=[\"issuers\"]\n",
    "    )\n",
    "except:\n",
    "    print('Database is already created')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting a nested dictionary {cik : { issuer : total_amount } }\n",
    "* {cik1 : { issuer1 : total_amount, issuer2 : total_amount ...etc}, cik2 : {} ..etc }\n",
    "* for each investment manager *cik* we get a dictionary of all of the companies it invested into = *issuer*\n",
    "* for each issuer company *issuer* we get a value corresponding to the **total amount** of stocks\n",
    "* you can obtain data for a desired year (1st quarter of 2021 - 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#list of all year (keys in all_years_urls)\n",
    "years = ['13F_2021.txt', '13F_2020.txt', '13F_2019.txt', '13F_2018.txt']\n",
    "\n",
    "data_dict = {} #nested dictionary for each CIK contains a dictionary of {issuer : total_amount}\n",
    "\n",
    "\n",
    "#networksCollection = db.createCollection(name = 'Networks') only 1st time run\n",
    "\n",
    "# getting the data frame for a given year \n",
    "for url in all_years_urls.get(years[0]): \n",
    "    page = requests.get(url)\n",
    "    data = page.text\n",
    "    soup = BeautifulSoup(data, \"lxml\")\n",
    "\n",
    "    cik_key = url.split('/')\n",
    "    cik_key = cik_key[-1].split('-')\n",
    "    cik_key = cik_key[0]\n",
    "    data_dict[cik_key] = {}\n",
    "    \n",
    "    stocklist = soup.find_all('infotable')\n",
    "\n",
    "    for s in stocklist:\n",
    "\n",
    "        if s.find(\"ns1:nameofissuer\") != None:\n",
    "            # Company name\n",
    "            n = s.find(\"ns1:nameofissuer\").string\n",
    "            if n in data_dict[cik_key].keys():\n",
    "                #Create only a record if the issuer is unique, oterwise sum the amount of stocks\n",
    "                data_dict[cik_key][n] = data_dict[cik_key].get(n) + int(s.find(\"ns1:shrsorprnamt\").find(\"ns1:sshprnamt\").string)# Company name\n",
    "            else:\n",
    "                data_dict[cik_key][n] = int(s.find(\"ns1:shrsorprnamt\").find(\"ns1:sshprnamt\").string)\n",
    "        \n",
    "        else:\n",
    "            n = s.find(\"nameofissuer\").string\n",
    "            if n in data_dict[cik_key].keys():\n",
    "                #Create only a record if the issuer is unique, oterwise sum the amount of stocks\n",
    "                data_dict[cik_key][n] = data_dict[cik_key].get(n) + int(s.find(\"shrsorprnamt\").find(\"sshprnamt\").string)\n",
    "            else:\n",
    "                data_dict[cik_key][n] = int(s.find(\"shrsorprnamt\").find(\"sshprnamt\").string)\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Graph Database\n",
    "* Nodes = InvestmentManagers and IssuerCompany\n",
    "* Edges = Investments (of the InvestmentManagers to IssuerCompanies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyArango.collection import Collection, Field, Edges\n",
    "from pyArango.graph import Graph, EdgeDefinition\n",
    "\n",
    "\n",
    "class InvestmentManager(Collection):\n",
    "    _fields = {\n",
    "        \"cik\": Field()\n",
    "    }\n",
    "    \n",
    "class IssuerComapny(Collection):\n",
    "    _fields = {\n",
    "        \"issuer\": Field()\n",
    "    }\n",
    "\n",
    "class Investments(Edges): \n",
    "    _fields = {\n",
    "        \"amount\": Field()\n",
    "    }\n",
    "\n",
    "class Networks(Graph) :\n",
    "    _edgeDefinitions = [EdgeDefinition('Investments', fromCollections=['InvestmentManagers'], toCollections=['IssuerCompany'])]\n",
    "    _orphanedCollections = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling the database - Nodes\n",
    "* needs to be run only once\n",
    "* try - except block -> in case the process was interrupted (error) and the doc was already added there would be a CreationError (violation of uniqueness constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for cik in data_dict.keys():\n",
    "    try:\n",
    "        db['investors'].insert({'cik': cik, '_key' : cik})\n",
    "        issuers_dict = data_dict.get(cik)\n",
    "        for issuer in issuers_dict.keys():\n",
    "            db['issuers'].insert({'issuer': issuer, '_key' : issuer})\n",
    "            db['investments'].inset({'_from': 'investors', '_to': 'issuer', 'amount' : isssuers_dict.get(issuer)})\n",
    "    except:\n",
    "        continue\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling the database - Edges\n",
    "* needs to be run only once\n",
    "* try - except block -> in case the process was interrupted (error) and the doc was already added there would be a CreationError (violation of uniqueness constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = db['investments']\n",
    "for cik in data_dict.keys():\n",
    "    issuers_dict = data_dict.get(cik)\n",
    "    for issuer in issuers_dict.keys(): \n",
    "        try:\n",
    "            doc = collection.createDocument()\n",
    "            doc['_from'] = 'InvestmentManagers/'+cik\n",
    "            if(issuer == None):\n",
    "                break\n",
    "            else:\n",
    "                doc['_to'] = 'IssuerCompany/'+issuer\n",
    "            if(issuers_dict.get(issuer) == None):\n",
    "                doc['amount'] = 1\n",
    "            else:\n",
    "                doc['amount'] = issuers_dict.get(issuer)\n",
    "            doc.save()\n",
    "        except CreationError: \n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ratings = \"\"\"\n",
    "WITH InvestmentMangers, IssuerCompany, Investments\n",
    "FOR issuer, edge IN 1..2 \n",
    "  OUTBOUND 'InvestmentManagers/1'\n",
    "  GRAPH 'Networks'\n",
    "  FILTER TO_NUMBER(edge.ratings) == 5\n",
    "  LIMIT 10\n",
    "  RETURN {\n",
    "        \"issuer\" : issuer.issuer,\n",
    "        \"rating\" : edge.amount\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "queryResult = db.AQLQuery(my_ratings, rawResults=True)\n",
    "for result in queryResult:\n",
    "    print(\"Issuer: \" + result[\"isuer\"])\n",
    "    print(\"Inverstment: \" + result[\"amount\"])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
