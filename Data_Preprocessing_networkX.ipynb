{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the biggest investment managers\n",
    "* scraping the website: https://www.advratings.com/top-asset-management-firms containing the list of the top asset mangement firms\n",
    "* processing the name of the of the company\n",
    "* storing the list of all the companies in funds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funds_list = []\n",
    "\n",
    "url = 'https://www.advratings.com/top-asset-management-firms'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "for row in soup.findAll('table')[0].tbody.findAll('tr'):\n",
    "    company = str(row.findAll('td')[1].contents)\n",
    "    company = re.split(r'<|>', company)\n",
    "    if(len(company) > 2):\n",
    "        #exluding any special chars and wite spaces from company names\n",
    "        company = ''.join(e for e in company[2] if e.isalnum())\n",
    "        funds_list.append(company.upper())\n",
    "    else:\n",
    "        company = re.split(r'([\\'|\\'])', company[0])\n",
    "        #exluding any special chars and wite spaces from company names\n",
    "        company = ''.join(e for e in company[2] if e.isalnum())\n",
    "        funds_list.append(company.upper())\n",
    "\n",
    "#deleting the first record (remainder of the header)\n",
    "funds_list = funds_list[1:]\n",
    "len(funds_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dictionary of {Year : URL list} \n",
    "* Getting path to all 13F-HR filing per quarter \n",
    "* Each file corresponds to quater 1, the files are for years 2021 - 2018 \n",
    "* Choosing only files from **funds_list** - list of the top asset investment managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_years_urls = {}\n",
    "path = 'https://www.sec.gov/Archives/'\n",
    "companies = []\n",
    "\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "\n",
    "file_2021 = open('/home/ivana/Environments/env/Data_Preprocessing/13F_2021.txt', 'r')\n",
    "file_2020 = open('/home/ivana/Environments/env//Data_Preprocessing/13F_2020.txt', 'r')\n",
    "file_2019 = open('/home/ivana/Environments/env//Data_Preprocessing/13F_2019.txt', 'r')\n",
    "file_2018 = open('/home/ivana/Environments/env//Data_Preprocessing/13F_2018.txt', 'r')\n",
    "\n",
    "files = [file_2021, file_2020, file_2019, file_2018]\n",
    "\n",
    "for file in files:\n",
    "    forms_url = []\n",
    "    for line in file:\n",
    "        \n",
    "        #parsing out the company name from the list\n",
    "        company = re.findall(r'13F-HR\\s*\\d*([\\D+\\s\\D+]*)\\s*\\d*', line)\n",
    "        \n",
    "        #string processing to get uniform formatting\n",
    "        company = ''.join(e for e in company)\n",
    "        company = company.replace(' ', '')\n",
    "        company = re.sub('\\d', '', company)\n",
    "        company = company.upper()\n",
    "\n",
    "        \n",
    "        #finding the investment managers that match the list of the top investment mangers *fund_list*\n",
    "        for name in funds_list:\n",
    "            if (company in name or name in company) and len(company) > 3:\n",
    "                splitted = line.split()\n",
    "                forms_url.append(path + splitted[-1])\n",
    "                \n",
    "    #adding a key:value pair to a dict. - contains \n",
    "    all_years_urls[file.name.split('/')[-1]] = forms_url\n",
    "\n",
    "#finding out how many \n",
    "len(all_years_urls.get('13F_2021.txt'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting a nested dictionary {cik : { issuer : total_amount } }\n",
    "* {cik1 : { issuer1 : total_amount, issuer2 : total_amount ...etc}, cik2 : {} ..etc }\n",
    "* for each investment manager *cik* we get a dictionary of all of the companies it invested into = *issuer*\n",
    "* for each issuer company *issuer* we get a value corresponding to the **total amount** of stocks\n",
    "* you can obtain data for a desired year (1st quarter of 2021 - 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#list of all year (keys in all_years_urls)\n",
    "years = ['13F_2021.txt', '13F_2020.txt', '13F_2019.txt', '13F_2018.txt']\n",
    "\n",
    "data_dict = {} #nested dictionary for each CIK contains a dictionary of {issuer : total_amount}\n",
    "\n",
    "\n",
    "#networksCollection = db.createCollection(name = 'Networks') only 1st time run\n",
    "\n",
    "# getting the data frame for a given year \n",
    "for url in all_years_urls.get(years[0]): \n",
    "    page = requests.get(url)\n",
    "    data = page.text\n",
    "    soup = BeautifulSoup(data, \"lxml\")\n",
    "\n",
    "    cik_key = url.split('/')\n",
    "    cik_key = cik_key[-1].split('-')\n",
    "    cik_key = cik_key[0]\n",
    "    data_dict[cik_key] = {}\n",
    "    \n",
    "    stocklist = soup.find_all('infotable')\n",
    "\n",
    "    for s in stocklist:\n",
    "\n",
    "        if s.find(\"ns1:nameofissuer\") != None:\n",
    "            # Company name\n",
    "            n = s.find(\"ns1:nameofissuer\").string\n",
    "            if n in data_dict[cik_key].keys():\n",
    "                #Create only a record if the issuer is unique, oterwise sum the amount of stocks\n",
    "                data_dict[cik_key][n] = data_dict[cik_key].get(n) + int(s.find(\"ns1:shrsorprnamt\").find(\"ns1:sshprnamt\").string)# Company name\n",
    "            else:\n",
    "                data_dict[cik_key][n] = int(s.find(\"ns1:shrsorprnamt\").find(\"ns1:sshprnamt\").string)\n",
    "        \n",
    "        else:\n",
    "            n = s.find(\"nameofissuer\").string\n",
    "            if n in data_dict[cik_key].keys():\n",
    "                #Create only a record if the issuer is unique, oterwise sum the amount of stocks\n",
    "                data_dict[cik_key][n] = data_dict[cik_key].get(n) + int(s.find(\"shrsorprnamt\").find(\"sshprnamt\").string)\n",
    "            else:\n",
    "                data_dict[cik_key][n] = int(s.find(\"shrsorprnamt\").find(\"sshprnamt\").string)\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Graphs with NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_nodes_from(list(data_dict.keys()), bipartite = 0)\n",
    "for cik in data_dict.keys():\n",
    "    issuers_dict = data_dict.get(cik)\n",
    "    G.add_nodes_from(list(issuers_dict.keys()), bipartite = 1)\n",
    "    edges = []\n",
    "    for issuer in issuers_dict:\n",
    "        tuple = (cik, issuer, {'amount' : issuers_dict.get(issuer)})\n",
    "        edges.append(tuple)\n",
    "    G.add_edges_from(edges)\n",
    "\n",
    "\n",
    "#print(G.edges)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
